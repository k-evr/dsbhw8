# TODO: Implement classification metrics using confusion matrix components
def calculate_metrics(TP, TN, FP, FN):
    """
    Calculate classification metrics from confusion matrix components
    """
    accuracy = precision = recall = f1 = 0
    # Calculate accuracy
    total = TP + TN + FP + FN
    accuracy = (TP + TN) / total if total > 0 else 0
    
    # Calculate precision
    precision = TP / (TP + FP) if (TP + FP) > 0 else 0
    
    # Calculate recall
    recall = TP / (TP + FN) if (TP + FN) > 0 else 0
    
    # Calculate F1-score
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    return accuracy, precision, recall, f1

# TODO: Calculate metrics using the confusion matrix from Exercise 3
accuracy, precision, recall, f1 = calculate_metrics(TP, TN, FP, FN)

print("\nClassification Metrics:")
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")




Classification Metrics:
Accuracy: 0.7000
Precision: 0.6667
Recall: 0.8000
F1-Score: 0.7273
